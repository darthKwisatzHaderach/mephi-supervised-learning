from sklearn.preprocessing import MinMaxScaler, StandardScaler
import numpy as np
import pandas as pd

# вектор признаков
X = np.array([[ 1000., -15.,  2.],
              [ 2500.,  10.,  1.],
              [ 3000.,  13., -1.]])

X_train = pd.DataFrame(X, columns=['f1','f2','f3'])

print("Исходные данные")
print(X_train)
print("\nСреднее значение по каждому столбцу")
print(X_train.mean(axis=0))

# Создание объекта класса (т.е. инициализация алгоритма)
# Алгоритм стандартизации
std = StandardScaler()

# Обучение (fit). На этапе обучения алгоритма стандартизации рассчитываются все необходимые значения
# для преобразования — стандартное отклонение и среднее значение для всех переменных
std.fit(X)

# Применение (predict для алгоритмов ML, transform для алгоритмов предобработки данных)
X_std = std.transform(X)

# Здесь нужно быть аккуратным, так как большинство алгоритмов библиотеки Scikit-learn,
# несмотря на, то что могут принимать как DataFrame, так и NumPy массивы,
# возвращают всегда NumPy массив. Поэтому если вы хотите дальше работать с DataFrame,
# необходимо явным образом его получить.
X_std = pd.DataFrame(X_std, columns=['f1','f2','f3'])

# Среднее значение по каждому столбцу
print("\nСреднее значение по каждому столбцу после масштабирования (применение алгоритма стандартизации)")
print(X_std.mean(axis=0).round(0))

# Среднее отклонение по каждому столбцу
print("\nСреднее отклонение по каждому столбцу")
print(X_std.std(axis=0).round())

# Применение алгоритма нормализации
mmsc = MinMaxScaler()
X_norm = mmsc.fit_transform(X_train) # type - numpy array

X_norm = pd.DataFrame(X_norm, columns=['f1','f2','f3'])

# Среднее значение по каждому столбцу
print("\nСреднее значение по каждому столбцу после масштабирования (применение алгоритма нормализации)")
print(X_norm.mean(axis=0))

# Среднее отклонение по каждому столбцу
print("\nСреднее отклонение по каждому столбцу")
print(X_norm.std(axis=0))